name: CI/CD Pipeline

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      lint_only:
        description: 'Run only linting checks'
        required: false
        default: false
        type: boolean
      test_only:
        description: 'Run only tests'
        required: false
        default: false
        type: boolean
      specific_file:
        description: 'Specific file to lint or test'
        required: false
        type: string
      test_path:
        description: 'Path to test directory or file'
        required: false
        default: 'tests/'
        type: string
      skip_docker:
        description: 'Skip Docker build'
        required: false
        default: false
        type: boolean

permissions:
  contents: write    # For push branch
  pull-requests: write    # For PR updates

jobs:
  lint:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history and all files
      - name: Debug repository contents
        run: |
          echo "Listing repository root contents:"
          ls -la
          echo "Checking for requirements files:"
          find . -maxdepth 3 -name "requirements*.txt" -o -name "pyproject.toml" | sort
          echo "Current working directory: $(pwd)"
          echo "Files in parent directory:"
          ls -la ..
      - name: Fix dependencies in requirements file
        run: |
          # Check if api/requirements.txt exists
          if [ -f api/requirements.txt ]; then
            echo "Fixing strawberry-graphql-fastapi reference in api/requirements.txt"
            # Remove any strawberry-graphql-fastapi references and ensure strawberry-graphql is properly specified
            sed -i 's/strawberry-graphql-fastapi>=0.171.1/# strawberry-graphql-fastapi removed - use strawberry-graphql instead/g' api/requirements.txt
            # Make sure we have the correct strawberry-graphql version
            grep -q "strawberry-graphql" api/requirements.txt || echo "strawberry-graphql>=0.171.1" >> api/requirements.txt
            echo "Modified api/requirements.txt:"
            cat api/requirements.txt
          fi
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel

          # Install Ruff
          echo "Installing Ruff..."
          pip install --no-cache-dir ruff
          ruff --version || { echo "ERROR: Ruff installation failed! Exiting..."; exit 1; }

          # Install essential tools
          echo "Installing essential linting tools..."
          pip install --upgrade mypy isort pyright || {
            echo "Retrying with --no-cache-dir..."
            pip install --no-cache-dir --upgrade mypy isort pyright
          }

          # Check and install project dependencies with better error handling
          echo "Installing project dependencies..."

          FOUND_DEPENDENCIES=false

          # Create a temporary file to log requirements discovery
          touch requirements_search_log.txt

          # More comprehensive search for requirements.txt and pyproject.toml
          echo "Searching for requirements files in repository..." | tee -a requirements_search_log.txt

          if [ -f requirements.txt ]; then
            echo "Found requirements.txt in root directory" | tee -a requirements_search_log.txt
            echo "Contents of requirements.txt:" | tee -a requirements_search_log.txt
            cat requirements.txt | tee -a requirements_search_log.txt
            pip install -r requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f requirements-dev.txt ]; then
            echo "Found requirements-dev.txt in root directory" | tee -a requirements_search_log.txt
            pip install -r requirements-dev.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f ai_models/requirements.txt ]; then
            echo "Found requirements.txt in ai_models directory" | tee -a requirements_search_log.txt
            pip install -r ai_models/requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f api/requirements.txt ]; then
            echo "Found requirements.txt in api directory" | tee -a requirements_search_log.txt
            pip install -r api/requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f pyproject.toml ]; then
            echo "Found pyproject.toml in root directory" | tee -a requirements_search_log.txt
            echo "Contents of pyproject.toml:" | tee -a requirements_search_log.txt
            cat pyproject.toml | tee -a requirements_search_log.txt

            # Check if poetry is needed based on pyproject.toml content
            if grep -q "\[tool.poetry\]" pyproject.toml; then
              echo "Installing dependencies using poetry" | tee -a requirements_search_log.txt
              pip install poetry
              poetry install && FOUND_DEPENDENCIES=true
            else
              echo "Using pip to install from pyproject.toml" | tee -a requirements_search_log.txt
              pip install -e . && FOUND_DEPENDENCIES=true
            fi
          fi

          # Strong fallback if no requirements files were found or all installations failed
          if [ "$FOUND_DEPENDENCIES" = false ]; then
            echo "WARNING: No dependency files found or all installations failed." | tee -a requirements_search_log.txt
            echo "Requirements discovery log:" | tee -a requirements_search_log.txt
            cat requirements_search_log.txt

            echo "Installing minimal set of dependencies to continue..." | tee -a requirements_search_log.txt
            # Install a minimal set of dependencies to continue
            pip install --upgrade pytest pytest-cov pytest-xdist pytest-asyncio
            # Make sure ruff is installed as a last resort
            pip install --no-cache-dir ruff
            echo "Minimal dependencies installed." | tee -a requirements_search_log.txt
          fi

          # Upload the requirements search log as an artifact for troubleshooting
          mkdir -p requirements_logs
          mv requirements_search_log.txt requirements_logs/

      - name: Upload requirements logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: requirements-logs-${{ github.run_id }}-${{ github.job }}
          path: requirements_logs/

      - name: Check Import Sorting
        run: isort --check-only .

      - name: Check if fix_linting_issues.py exists
        id: check-script
        run: |
          if [ -f "fix_linting_issues.py" ]; then
            echo "script_exists=true" >> $GITHUB_OUTPUT
            echo "Script found, proceeding..."
          else
            echo "script_exists=false" >> $GITHUB_OUTPUT
            echo "Warning: fix_linting_issues.py not found!"
          fi

      - name: Run fix_linting_issues.py
        if: steps.check-script.outputs.script_exists == 'true'
        run: |
          echo "Running fix_linting_issues.py..."
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Branch handling
          if [ -n "${GITHUB_HEAD_REF}" ]; then
            echo "Checking out PR branch: ${GITHUB_HEAD_REF}"
            git checkout "${GITHUB_HEAD_REF}" || {
              echo "Failed to checkout PR branch"
              exit 1
            }
          else
            BRANCH_NAME=${GITHUB_REF#refs/heads/}
            echo "Checking out branch: ${BRANCH_NAME}"
            git checkout "${BRANCH_NAME}" || {
              echo "Failed to checkout branch"
              exit 1
            }
          fi

          # Run the script
          python fix_linting_issues.py --verbose

          # Committing and pushing changes has been removed from this step.
          # The script will still run and may modify files in the runner's workspace.
        continue-on-error: true

      - name: Fix Imports with Ruff and Isort
        id: fix-imports
        run: |
          echo "Running Ruff in fix mode for import sorting and other fixes..."
          ruff check --fix . || echo "Ruff command finished (may have encountered issues, or made no changes)."
          echo "Running isort in fix mode for import sorting..."
          isort . || echo "Isort command finished (may have encountered issues, or made no changes)."

          echo "Checking for changes after ruff and isort..."
          if [ -n "$(git diff --name-only)" ]; then
            echo "Ruff or isort made changes. Setting fixed=true"
            echo "fixed=true" >> $GITHUB_OUTPUT
          else
            echo "Neither ruff nor isort made changes. Setting fixed=false"
            echo "fixed=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      # The 'Commit and Push Import Fixes' step has been removed to prevent automated commits.
      # Ruff and Isort will still run and may modify files in the runner's workspace,
      # but these changes will not be committed.

      - name: Notify Developer
        if: failure()
        run: |
          {
            echo "::error::Ruff auto-fix encountered issues:"
            echo "::group::Error Details"
            echo "- Check the Ruff output above for specific formatting issues"
            echo "- Review failing files manually"
            echo "- Consider running 'ruff check --fix' locally"
            echo ""
            echo "To fix these issues locally, run:"
            echo "```bash"
            echo "# Install required tools if you don't have them"
            echo "pip install isort ruff"
            echo ""
            echo "# Fix all issues automatically using our custom script"
            echo "python fix_linting_issues.py --verbose"
            echo ""
            echo "# Or fix specific files"
            echo "python fix_linting_issues.py path/to/file.py --verbose"
            echo ""
            echo "# Alternatively, use Ruff directly"
            echo "ruff check . --fix"
            echo "```"
            echo "::endgroup::"

            if [ -n "$(git diff --name-only)" ]; then
              echo "::group::Modified Files"
              git diff --name-only
              echo "::endgroup::"
            fi
          } >> $GITHUB_STEP_SUMMARY

          # Create a comment on the PR if this is a pull request
          if [ -n "$GITHUB_EVENT_NAME" ] && [ "$GITHUB_EVENT_NAME" = "pull_request" ]; then
            echo "Creating comment on PR..."

            # Create a temporary file for the PR comment
            echo "## Linting Issues Detected ðŸ”" > pr_comment.md
            echo "" >> pr_comment.md
            echo "The CI workflow detected linting issues that need to be fixed. The workflow attempted to fix them automatically but encountered too many issues." >> pr_comment.md
            echo "" >> pr_comment.md
            echo "### How to fix:" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "1. Run our linting fix script locally:" >> pr_comment.md
            echo "   \`\`\`bash" >> pr_comment.md
            echo "   # Install required tools if you don't have them" >> pr_comment.md
            echo "   pip install isort ruff" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "   # Fix all issues automatically using our custom script" >> pr_comment.md
            echo "   python fix_linting_issues.py --verbose" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "   # Or fix specific files" >> pr_comment.md
            echo "   python fix_linting_issues.py path/to/file.py --verbose" >> pr_comment.md
            echo "   \`\`\`" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "2. Commit and push the changes" >> pr_comment.md
            echo "3. The CI workflow will run again and should pass" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "### Specific files that need attention:" >> pr_comment.md
            echo "- \`scripts/sues.py\` (mentioned in the error)" >> pr_comment.md
            echo "- Other Python files with formatting issues" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "For more details, check the workflow logs." >> pr_comment.md

            # Use GitHub API to post comment (requires GITHUB_TOKEN)
            PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = "/" } ; { print $3 }')
            COMMENT_BODY=$(cat pr_comment.md | jq -Rs .)
            curl -s -X POST \
              -H "Authorization: token ${{ github.token }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
              -d "{\"body\": $COMMENT_BODY}"
          fi

      - name: Run Ruff (Check Only)
        run: |
          echo "Running Ruff in check-only mode..."
          ruff check .
        continue-on-error: true

      - name: Run isort (check only)
        run: isort --check-only .
      - name: Run mypy
        run: mypy .

  lint_and_test:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: ${{ !github.event.inputs.test_only }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history and all files

      - name: Debug repository contents
        run: |
          echo "Listing repository root contents:"
          ls -la
          echo "Checking for requirements files:"
          find . -maxdepth 3 -name "requirements*.txt" -o -name "pyproject.toml" | sort
          echo "Current working directory: $(pwd)"
          echo "Files in parent directory:"
          ls -la ..

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip

      - name: Install dependencies
        run: |
          # Clean up any existing .egg-info directories to prevent conflicts
          find . -type d -name "*.egg-info" -exec rm -rf {} + || true
          python -m pip install --upgrade pip setuptools wheel

          # Install Ruff
          echo "Installing Ruff..."
          pip install --no-cache-dir ruff
          ruff --version || { echo "ERROR: Ruff installation failed! Exiting..."; exit 1; }

          # Install test tools with error handling
          echo "Installing essential test tools..."
          pip install --upgrade pytest pytest-cov pytest-xdist pytest-asyncio || {
            echo "Failed to install test tools on first attempt, retrying with --no-cache-dir"
            pip install --no-cache-dir --upgrade pytest pytest-cov pytest-xdist pytest-asyncio
          }

          # Create a temporary file to log requirements discovery
          touch requirements_search_log.txt

          # More comprehensive search for requirements.txt and pyproject.toml
          echo "Searching for requirements files in repository..." | tee -a requirements_search_log.txt

          FOUND_DEPENDENCIES=false

          if [ -f requirements.txt ]; then
            echo "Found requirements.txt in root directory" | tee -a requirements_search_log.txt
            echo "Contents of requirements.txt:" | tee -a requirements_search_log.txt
            cat requirements.txt | tee -a requirements_search_log.txt
            pip install -r requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f requirements-dev.txt ]; then
            echo "Found requirements-dev.txt in root directory" | tee -a requirements_search_log.txt
            pip install -r requirements-dev.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f ai_models/requirements.txt ]; then
            echo "Found requirements.txt in ai_models directory" | tee -a requirements_search_log.txt
            pip install -r ai_models/requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f api/requirements.txt ]; then
            echo "Found requirements.txt in api directory" | tee -a requirements_search_log.txt
            pip install -r api/requirements.txt && FOUND_DEPENDENCIES=true
          fi

          if [ -f pyproject.toml ]; then
            echo "Found pyproject.toml in root directory" | tee -a requirements_search_log.txt
            echo "Contents of pyproject.toml:" | tee -a requirements_search_log.txt
            cat pyproject.toml | tee -a requirements_search_log.txt

            # Check if poetry is needed based on pyproject.toml content
            if grep -q "\[tool.poetry\]" pyproject.toml; then
              echo "Installing dependencies using poetry" | tee -a requirements_search_log.txt
              pip install poetry
              poetry install && FOUND_DEPENDENCIES=true
            else
              echo "Using pip to install from pyproject.toml" | tee -a requirements_search_log.txt
              pip install -e . && FOUND_DEPENDENCIES=true
            fi
          fi

          # Install the package itself in development mode
          echo "Installing package in development mode..."
          pip install -e . || echo "Failed to install package in development mode, continuing anyway"

          # Strong fallback if no requirements files were found or all installations failed
          if [ "$FOUND_DEPENDENCIES" = false ]; then
            echo "WARNING: No dependency files found or all installations failed." | tee -a requirements_search_log.txt
            echo "Requirements discovery log:" | tee -a requirements_search_log.txt
            cat requirements_search_log.txt

            echo "Installing minimal set of dependencies to continue..." | tee -a requirements_search_log.txt
            # Install a minimal set of dependencies to continue
            pip install --upgrade pytest pytest-cov pytest-xdist pytest-asyncio
            # Ruff is already installed in a previous step
            echo "Minimal dependencies installed." | tee -a requirements_search_log.txt
          fi

          # Upload the requirements search log as an artifact for troubleshooting
          mkdir -p requirements_logs
          mv requirements_search_log.txt requirements_logs/

      - name: Upload requirements logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: requirements-logs-${{ github.run_id }}-${{ github.job }}
          path: requirements_logs/

      - name: Create junit directory
        run: mkdir -p junit
      - name: Run tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          TEST_PATH="${{ github.event.inputs.test_path }}"

          if [ -n "${{ github.event.inputs.specific_file }}" ]; then
            TEST_PATH="${{ github.event.inputs.specific_file }}"
            echo "Running tests for specific file: $TEST_PATH"
          else
            echo "Running tests for path: $TEST_PATH"
          fi

          # Run pytest with coverage and output to junit
          python -m pytest $TEST_PATH -v \
            --import-mode=importlib \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=90 \
            --junitxml=junit/test-results.xml || {
              echo "Warning: Some tests failed, but continuing..."
            }

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ github.run_id }}-${{ github.job }}
          path: junit/test-results.xml

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-${{ github.run_id }}
          path: coverage.xml
