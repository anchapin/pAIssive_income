name: Python Tests (Reusable)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      python-version:
        description: 'Python version to use'
        required: false
        default: '3.12'
        type: string
      test-path:
        description: 'Path to test files'
        required: false
        default: 'tests'
        type: string
  workflow_call:
    inputs:
      python-version:
        description: 'Python version to use'
        required: false
        default: '3.12'
        type: string
      test-path:
        description: 'Path to test files'
        required: false
        default: 'tests'
        type: string
  workflow_run:
    workflows: ["Gradual Lint Check"]
    types:
      - completed

jobs:
  test:
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version || '3.12' }}

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.uv
            .pytest_cache
          key: ${{ runner.os }}-uv-test-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-uv-test-

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          # Cleanup old distributions
          find . -type d -name "*.egg-info" -exec rm -rf {} + || true
          find . -type d -name "*.dist-info" -exec rm -rf {} + || true
          find . -name "*.egg" -exec rm -f {} + || true

          # Create virtual environment with uv
          uv venv .venv || {
            echo "Failed to create virtual environment with uv. Falling back to Python's venv module..."
            python -m venv .venv
          }

          # Activate virtual environment
          source .venv/bin/activate

          # Install core test dependencies first (faster)
          echo "Installing core test dependencies..."
          uv pip install pytest pytest-cov pytest-xdist pytest-asyncio aiohttp>=3.9.0 || {
            echo "Failed to install core dependencies with uv. Trying with pip..."
            python -m pip install pytest pytest-cov pytest-xdist pytest-asyncio aiohttp>=3.9.0
          }

          # Install project requirements (only essential ones for testing)
          echo "Installing project requirements..."
          if [ -f requirements.txt ]; then
            # Install only essential dependencies for testing to speed up the process
            uv pip install -r requirements.txt --no-deps || {
              echo "Failed to install requirements.txt with uv. Trying with pip..."
              python -m pip install -r requirements.txt --no-deps
            }
            # Install missing dependencies that are actually needed
            uv pip install fastapi uvicorn pydantic redis python-multipart httpx flask || true
          fi

          # Install the package in development mode (minimal)
          echo "Installing package in development mode..."
          uv pip install -e . --no-deps || {
            echo "Failed to install package with uv. Trying with pip..."
            python -m pip install -e . --no-deps
          }

      - name: Create junit directory
        run: mkdir -p junit

      - name: Run tests with coverage
        env:
          PYTHONPATH: ${{ github.workspace }}
        timeout-minutes: 20
        run: |
          # Activate virtual environment
          source .venv/bin/activate

          # Run tests with pytest (optimized for speed)
          # Use the coverage threshold of 15% (consistent with other configurations)
          echo "Starting test execution..."
          pytest ${{ inputs.test-path || 'tests' }} \
            -n auto \
            --tb=short \
            --import-mode=importlib \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=15 \
            --junitxml=junit/test-results.xml \
            --maxfail=10 \
            --disable-warnings \
            --ignore=tests/ai_models/adapters/test_mcp_adapter.py \
            --ignore=tests/test_mcp_import.py \
            --ignore=tests/test_mcp_top_level_import.py \
            --ignore=tests/test_crewai_agents.py \
            --ignore=tests/test_mem0_integration.py \
            --ignore=ai_models/artist_rl/test_artist_rl.py \
            --ignore=mock_mcp \
            --ignore=mock_crewai \
            --ignore=mock_mem0 \
            || {
              echo "Tests failed or coverage below 15%. Checking if any tests ran..."
              if [ -f junit/test-results.xml ]; then
                echo "Test results file exists, continuing with upload..."
              else
                echo "No test results found, creating minimal results file..."
                mkdir -p junit
                echo '<?xml version="1.0" encoding="UTF-8"?><testsuites><testsuite name="minimal" tests="1" failures="0"><testcase name="placeholder"/></testsuite></testsuites>' > junit/test-results.xml
              fi
              exit 1
            }

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ github.run_id }}-${{ github.job }}
          path: junit/test-results.xml

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ github.run_id }}
          path: coverage.xml
